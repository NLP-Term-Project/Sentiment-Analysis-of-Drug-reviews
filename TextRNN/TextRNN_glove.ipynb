{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TextRNN_glove",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzidUQpqj4z5",
        "colab_type": "code",
        "outputId": "e8aaac34-9339-4000-cd54-46e35d41d0bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        }
      },
      "source": [
        "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00462/drugsCom_raw.zip\n",
        "!unzip drugsCom_raw.zip\n",
        "!rm *.zip\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-11-27 15:52:53--  https://archive.ics.uci.edu/ml/machine-learning-databases/00462/drugsCom_raw.zip\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 42989872 (41M) [application/x-httpd-php]\n",
            "Saving to: ‘drugsCom_raw.zip’\n",
            "\n",
            "drugsCom_raw.zip    100%[===================>]  41.00M  14.4MB/s    in 2.9s    \n",
            "\n",
            "2019-11-27 15:53:02 (14.4 MB/s) - ‘drugsCom_raw.zip’ saved [42989872/42989872]\n",
            "\n",
            "Archive:  drugsCom_raw.zip\n",
            "  inflating: drugsComTest_raw.tsv    \n",
            "  inflating: drugsComTrain_raw.tsv   \n",
            "drugsComTest_raw.tsv  drugsComTrain_raw.tsv  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASu9d7p6m-fo",
        "colab_type": "code",
        "outputId": "1521578c-0a33-473c-d0c8-0e7768212566",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "source": [
        "!wget nlp.stanford.edu/data/glove.6B.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-11-27 15:53:20--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2019-11-27 15:53:20--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2019-11-27 15:53:21--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  2.11MB/s    in 6m 30s  \n",
            "\n",
            "2019-11-27 15:59:51 (2.11 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdWsCJObruvC",
        "colab_type": "code",
        "outputId": "f388c861-da3e-4b4b-a35d-1a5d05c3cea1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "!unzip glove.6B.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KkQWMli4T9b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47WRDurvor3S",
        "colab_type": "code",
        "outputId": "665dfc8f-88d5-40b4-8d66-d4e3575be9b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import keras\n",
        "from keras.preprocessing.text import Tokenizer,  text_to_word_sequence\n",
        "from keras.layers import Embedding, Input, Dense, LSTM,Bidirectional\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "import nltk\n",
        "from gensim.models import KeyedVectors\n",
        "nltk.download('stopwords')\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import re\n",
        "from keras import regularizers\n",
        "import tensorflow as tf\n",
        "from nltk import tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
        "from random import shuffle\n",
        "from keras.models import load_model\n",
        "%tensorflow_version 1.x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-THSB8bSoyes",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_FEATURES=200000\n",
        "MAX_SENT_LEN=100\n",
        "EMBED_SIZE=100\n",
        "NUM_EPOCHS=25\n",
        "REG_PARAM = 1e-13\n",
        "OUTPUT_DIM = 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UY9cx4QhH5HG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataGenerator(keras.utils.Sequence):\n",
        "    'Generates data for Keras'\n",
        "    def __init__(self, list_IDs, labels, batch_size=32, dim=(32,32,32),\n",
        "                 n_classes=3, shuffle=True):\n",
        "        'Initialization'\n",
        "        self.dim = dim\n",
        "        self.batch_size = batch_size\n",
        "        self.labels = labels\n",
        "        self.list_IDs = list_IDs\n",
        "        self.n_classes = n_classes\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        'Denotes the number of batches per epoch'\n",
        "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generate one batch of data'\n",
        "        # Generate indexes of the batch\n",
        "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "\n",
        "        # Find list of IDs\n",
        "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
        "\n",
        "        # Generate data\n",
        "        X, y = self.__data_generation(list_IDs_temp)\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        'Updates indexes after each epoch'\n",
        "        self.indexes = np.arange(len(self.list_IDs))\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __data_generation(self, list_IDs_temp):\n",
        "        'Generates data containing batch_size samples' # X : (n_samples, *dim)\n",
        "        # Initialization\n",
        "        X = np.empty((self.batch_size, *self.dim))\n",
        "        y = np.empty((self.batch_size), dtype=int)\n",
        "\n",
        "        # Generate data\n",
        "        for i, ID in enumerate(list_IDs_temp):\n",
        "            # Store sample\n",
        "            X[i,] = np.load('data/out' + str(ID) + '.npy').reshape(MAX_SENT_LEN,)\n",
        "\n",
        "            # Store class\n",
        "            y[i] = self.labels[ID]\n",
        "\n",
        "        return X, keras.utils.to_categorical(y, num_classes=self.n_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImPscyQKI1Tc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def f1(y_true, y_pred):\n",
        "    def recall(y_true, y_pred):\n",
        "        \"\"\"Recall metric.\n",
        "\n",
        "        Only computes a batch-wise average of recall.\n",
        "\n",
        "        Computes the recall, a metric for multi-label classification of\n",
        "        how many relevant items are selected.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n",
        "\n",
        "    def precision(y_true, y_pred):\n",
        "        \"\"\"Precision metric.\n",
        "\n",
        "        Only computes a batch-wise average of precision.\n",
        "\n",
        "        Computes the precision, a metric for multi-label classification of\n",
        "        how many selected items are relevant.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        return precision\n",
        "    precision = precision(y_true, y_pred)\n",
        "    recall = recall(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yyT1Axjo4NH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def embed_matrix(word_index,EMBED_DIR='glove.6B.100d.txt'):\n",
        "    print(\"Loading embeddings from \",EMBED_DIR)\n",
        "    embeddings_index = {}\n",
        "    f = open(EMBED_DIR,'r')\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        coefs = np.asarray(values[-EMBED_SIZE:], dtype='float32')\n",
        "        word = ''.join(values[:-EMBED_SIZE])\n",
        "        embeddings_index[word] = coefs\n",
        "    f.close()\n",
        "    print('Total %s word vectors.' % len(embeddings_index))\n",
        "    embedding_matrix = np.zeros((len(word_index) + 1, EMBED_SIZE))\n",
        "    absent_words = 0\n",
        "    for word, i in word_index.items():\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            # words not found in embedding index will be all-zeros.\n",
        "            embedding_matrix[i] = embedding_vector\n",
        "        else:\n",
        "            absent_words += 1\n",
        "    print('Total absent words are', absent_words, 'which is', \"%0.2f\" % (absent_words * 100 / len(word_index)), '% of total words')\n",
        "    return embedding_matrix\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVt2E1Zmo_kZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(mode='train'):\n",
        "    if mode=='train':\n",
        "        df = pd.read_csv('drugsComTrain_raw.tsv',sep='\\t')\n",
        "        to_remove = np.random.choice(df[df['rating']>=7].index,size=92510,replace=False)\n",
        "        df = df.drop(to_remove).reset_index()\n",
        "        to_remove = np.random.choice(df[df['rating']<=4].index,size=25719,replace=False)\n",
        "        df = df.drop(to_remove).reset_index()\n",
        "        if OUTPUT_DIM==3:\n",
        "          df = df.replace(to_replace={1:'negative',2:'negative',3:'negative',4:'negative',5:'neutral',6:'neutral',7:'positive',8:'positive',9:'positive',10:'positive'})\n",
        "          df = df.replace(to_replace={'positive':2,'neutral':1,'negative':0})\n",
        "        return pd.DataFrame(df['review']),df['rating'].to_numpy()\n",
        "    if mode=='test':\n",
        "        df = pd.read_csv('drugsComTest_raw.tsv', sep='\\t')\n",
        "        if OUTPUT_DIM==3:\n",
        "          df = df.replace(to_replace={1:'negative',2:'negative',3:'negative',4:'negative',5:'neutral',6:'neutral',7:'positive',8:'positive',9:'positive',10:'positive'})\n",
        "          df = df.replace(to_replace={'positive':2,'neutral':1,'negative':0})\n",
        "        return pd.DataFrame(df['review']), pd.get_dummies(df['rating']).to_numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgifMn04pP2S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_str(string):\n",
        "    \"\"\"\n",
        "    Tokenization/string cleaning for dataset\n",
        "    Every dataset is lower cased except\n",
        "    \"\"\"\n",
        "    st_w = ['ourselves', 'hers', 'between', 'yourself', 'again', 'there', 'about', 'once', 'during', 'out',\n",
        "            'having', 'with', 'they', 'own', 'an', 'be', 'some', 'for','its', 'yours', 'such', 'into', 'of', \n",
        "            'itself', 'other', 'is', 's', 'am', 'or', 'who', 'as', 'from', 'him', 'each', 'the', 'themselves', 'until', \n",
        "            'below',  'we', 'these', 'your', 'his', 'through', 'me', 'were', 'her',  'himself', \n",
        "            'this', 'down',  'our', 'their', 'while', 'above', 'both', 'up', 'to', 'ours', 'she', 'all', \n",
        "             'when', 'at', 'any', 'before', 'them', 'same', 'and', 'been', 'have', 'in', 'will', 'on',  \n",
        "            'yourselves', 'then', 'that', 'what', 'over', 'why', 'so', 'now', 'under', \n",
        "            'he', 'you', 'herself', 'just', 'where', 'too', 'only', 'myself', 'which', 'those', 'i', 'after', \n",
        "            'few', 'whom', 'being', 'if', 'theirs', 'my',  'a', 'by', 'doing', 'it', 'how',  'here', 'than']\n",
        "    try:\n",
        "        string = re.sub(r\"\\\\\", \"\", string)    \n",
        "        string = re.sub(r\"\\'\", \"\", string)    \n",
        "        string = re.sub(r\"\\\"\", \"\", string) \n",
        "        string = re.sub(r\"&#039;\", \"'\",string)\n",
        "        string = re.sub(r\"\\r\",\"\",string)\n",
        "        string = re.sub(r\"\\n\",\"\",string)\n",
        "        string = string.split()\n",
        "        string = ' '.join([w for w in string if w not in st_w])\n",
        "    except:\n",
        "        print(string)\n",
        "    return string.strip().lower()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNI-aRYEpRgT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "texts = []\n",
        "train,labels = load_data('train')\n",
        "for idx in range(train['review'].shape[0]):\n",
        "    text = clean_str(train['review'][idx])\n",
        "    texts.append(text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDYZyqZwpTCp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer(num_words=MAX_FEATURES, oov_token=True)\n",
        "tokenizer.fit_on_texts(texts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjXioAxDpcec",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = np.zeros((len(texts), MAX_SENT_LEN), dtype='int32')\n",
        "for i, sent in enumerate(texts):\n",
        "    wordTokens = text_to_word_sequence(sent)\n",
        "    k=0\n",
        "    for _, word in enumerate(wordTokens):\n",
        "        try:\n",
        "          if k<MAX_SENT_LEN:\n",
        "              data[i,k] = tokenizer.word_index[word]\n",
        "              k=k+1\n",
        "        except:\n",
        "              print(word)\n",
        "              pass\n",
        "for i in range(len(data)):\n",
        "  np.save(\"data/out\"+str(i),data[i])              "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTiKAUU_HmQi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "partition = {}\n",
        "idx = np.arange(len(data))\n",
        "np.random.shuffle(idx)\n",
        "train_samples = int(0.8*(len(data)))\n",
        "partition['train']=idx[:train_samples]\n",
        "partition['validation'] = idx[train_samples:]\n",
        "label_dict = {}\n",
        "for i in range(len(data)):\n",
        "  label_dict[i] = labels[i]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJnZiokWHo-f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "params = {'dim': (MAX_SENT_LEN,),\n",
        "          'batch_size': 500,\n",
        "          'n_classes': OUTPUT_DIM,\n",
        "          'shuffle': True}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gwa9nat0Hpzx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_generator = DataGenerator(partition['train'], label_dict, **params)\n",
        "validation_generator = DataGenerator(partition['validation'], label_dict, **params)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xaJZgQklph9_",
        "colab_type": "code",
        "outputId": "cf638b00-f3f8-4abc-ef3a-bf1664eecbc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        }
      },
      "source": [
        "l2_reg = regularizers.l2(REG_PARAM)\n",
        "word_index= tokenizer.word_index\n",
        "embedding_matrix = embed_matrix(word_index)\n",
        "embedding_layer = Embedding(len(word_index) + 1,EMBED_SIZE,weights=[embedding_matrix], input_length=MAX_SENT_LEN, trainable=False)\n",
        "word_input = Input(shape=(MAX_SENT_LEN,), dtype='float32')\n",
        "word_sequences = embedding_layer(word_input)\n",
        "word_lstm = Bidirectional(LSTM(150, return_sequences=False, kernel_regularizer=l2_reg))(word_sequences)\n",
        "preds = Dense(OUTPUT_DIM,activation='softmax')(word_lstm)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading embeddings from  glove.6B.100d.txt\n",
            "Total 400000 word vectors.\n",
            "Total absent words are 9957 which is 31.73 % of total words\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HaLmlewpj7e",
        "colab_type": "code",
        "outputId": "f8b83dd6-e0cb-4e65-c2b5-d704981ba25f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 921
        }
      },
      "source": [
        "model = Model(word_input,preds)\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['acc',f1])\n",
        "earlystop = EarlyStopping(monitor='val_loss',min_delta=0,patience=10,verbose=0,restore_best_weights=True)\n",
        "checkpoint = ModelCheckpoint('textrnn.h5', verbose=0, monitor='val_loss',save_best_only=True, mode='auto') \n",
        "history = model.fit_generator(generator=training_generator,\n",
        "                    validation_data=validation_generator,\n",
        "                    use_multiprocessing=True,\n",
        "                    epochs =NUM_EPOCHS,callbacks=[checkpoint,earlystop])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Epoch 1/25\n",
            "68/68 [==============================] - 34s 503ms/step - loss: 1.0671 - acc: 0.4204 - f1: 0.0935 - val_loss: 1.0359 - val_acc: 0.4612 - val_f1: 0.1597\n",
            "Epoch 2/25\n",
            "68/68 [==============================] - 30s 448ms/step - loss: 1.0009 - acc: 0.4973 - f1: 0.3087 - val_loss: 0.9947 - val_acc: 0.4956 - val_f1: 0.3520\n",
            "Epoch 3/25\n",
            "68/68 [==============================] - 31s 453ms/step - loss: 0.9554 - acc: 0.5309 - f1: 0.4040 - val_loss: 0.9542 - val_acc: 0.5288 - val_f1: 0.4166\n",
            "Epoch 4/25\n",
            "68/68 [==============================] - 31s 454ms/step - loss: 0.9250 - acc: 0.5520 - f1: 0.4522 - val_loss: 0.9442 - val_acc: 0.5234 - val_f1: 0.4400\n",
            "Epoch 5/25\n",
            "68/68 [==============================] - 31s 453ms/step - loss: 0.8978 - acc: 0.5714 - f1: 0.4885 - val_loss: 0.9020 - val_acc: 0.5747 - val_f1: 0.4901\n",
            "Epoch 6/25\n",
            "68/68 [==============================] - 31s 458ms/step - loss: 0.8813 - acc: 0.5819 - f1: 0.5066 - val_loss: 0.9207 - val_acc: 0.5509 - val_f1: 0.4902\n",
            "Epoch 7/25\n",
            "68/68 [==============================] - 31s 451ms/step - loss: 0.8495 - acc: 0.6018 - f1: 0.5474 - val_loss: 0.8715 - val_acc: 0.5886 - val_f1: 0.5267\n",
            "Epoch 8/25\n",
            "68/68 [==============================] - 31s 452ms/step - loss: 0.8184 - acc: 0.6192 - f1: 0.5745 - val_loss: 0.8782 - val_acc: 0.5772 - val_f1: 0.5271\n",
            "Epoch 9/25\n",
            "68/68 [==============================] - 31s 451ms/step - loss: 0.7889 - acc: 0.6386 - f1: 0.6006 - val_loss: 0.8664 - val_acc: 0.5922 - val_f1: 0.5538\n",
            "Epoch 10/25\n",
            "68/68 [==============================] - 30s 444ms/step - loss: 0.7578 - acc: 0.6583 - f1: 0.6285 - val_loss: 0.8463 - val_acc: 0.6052 - val_f1: 0.5654\n",
            "Epoch 11/25\n",
            "68/68 [==============================] - 31s 454ms/step - loss: 0.7321 - acc: 0.6722 - f1: 0.6476 - val_loss: 0.8501 - val_acc: 0.6127 - val_f1: 0.5881\n",
            "Epoch 12/25\n",
            "68/68 [==============================] - 31s 450ms/step - loss: 0.6920 - acc: 0.6981 - f1: 0.6775 - val_loss: 0.8582 - val_acc: 0.6084 - val_f1: 0.5914\n",
            "Epoch 13/25\n",
            "68/68 [==============================] - 30s 444ms/step - loss: 0.6493 - acc: 0.7172 - f1: 0.7005 - val_loss: 0.8701 - val_acc: 0.6166 - val_f1: 0.5995\n",
            "Epoch 14/25\n",
            "68/68 [==============================] - 30s 446ms/step - loss: 0.6193 - acc: 0.7344 - f1: 0.7227 - val_loss: 0.8597 - val_acc: 0.6213 - val_f1: 0.6043\n",
            "Epoch 15/25\n",
            "68/68 [==============================] - 31s 451ms/step - loss: 0.5667 - acc: 0.7634 - f1: 0.7543 - val_loss: 0.8827 - val_acc: 0.6231 - val_f1: 0.6127\n",
            "Epoch 16/25\n",
            "68/68 [==============================] - 30s 446ms/step - loss: 0.5275 - acc: 0.7843 - f1: 0.7761 - val_loss: 0.8947 - val_acc: 0.6348 - val_f1: 0.6224\n",
            "Epoch 17/25\n",
            "68/68 [==============================] - 30s 440ms/step - loss: 0.4737 - acc: 0.8090 - f1: 0.8045 - val_loss: 0.9097 - val_acc: 0.6329 - val_f1: 0.6252\n",
            "Epoch 18/25\n",
            "68/68 [==============================] - 31s 455ms/step - loss: 0.4162 - acc: 0.8350 - f1: 0.8320 - val_loss: 0.9839 - val_acc: 0.6371 - val_f1: 0.6320\n",
            "Epoch 19/25\n",
            "68/68 [==============================] - 31s 453ms/step - loss: 0.3699 - acc: 0.8587 - f1: 0.8565 - val_loss: 0.9932 - val_acc: 0.6452 - val_f1: 0.6411\n",
            "Epoch 20/25\n",
            "68/68 [==============================] - 30s 448ms/step - loss: 0.3270 - acc: 0.8761 - f1: 0.8744 - val_loss: 1.0368 - val_acc: 0.6404 - val_f1: 0.6387\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_duH9aH4sFtE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test, test_labels = load_data('test')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbYv3iRfZqgV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_texts=[]\n",
        "for idx in range(test['review'].shape[0]):\n",
        "    text = clean_str(test['review'][idx])\n",
        "    test_texts.append(text)\n",
        "\n",
        "test_data = np.zeros((len(test_texts), MAX_SENT_LEN), dtype='int32')\n",
        "for i, sent in enumerate(test_texts):\n",
        "    wordTokens = text_to_word_sequence(sent)\n",
        "    k=0\n",
        "    for _, word in enumerate(wordTokens):\n",
        "        try:\n",
        "            if k<MAX_SENT_LEN:\n",
        "                test_data[i,k] = tokenizer.word_index[word]\n",
        "                k=k+1\n",
        "        except:\n",
        "            # print(word)\n",
        "            pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGC4Wz9pZ1pn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = model.predict(test_data,batch_size=1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4D4v6b7HKUq",
        "colab_type": "code",
        "outputId": "b0613d8c-d0f3-4dd4-e42b-bcff6cb08217",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        }
      },
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report,roc_auc_score\n",
        "pred_labels = np.argmax(pred,axis=1)\n",
        "act_labels = np.argmax(test_labels,axis=1)\n",
        "print('Acc: ',accuracy_score(act_labels,pred_labels))\n",
        "print('F1: ',f1_score(act_labels,pred_labels,average='weighted'))\n",
        "print(confusion_matrix(act_labels,pred_labels))\n",
        "print(classification_report(act_labels,pred_labels))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Acc:  0.6157608897816464\n",
            "F1:  0.6672794246341747\n",
            "[[ 8040  4033  1424]\n",
            " [ 1087  2830   912]\n",
            " [ 3392  9811 22237]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.60      0.62     13497\n",
            "           1       0.17      0.59      0.26      4829\n",
            "           2       0.90      0.63      0.74     35440\n",
            "\n",
            "    accuracy                           0.62     53766\n",
            "   macro avg       0.57      0.60      0.54     53766\n",
            "weighted avg       0.77      0.62      0.67     53766\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}